# =============================================================================
# Docker Compose - Nexus Backend (Isolated Stack)
# =============================================================================
# This is the SOURCE OF TRUTH for running the backend locally.
#
# ISOLATION: This stack uses its own network and volumes, completely
# independent from any other Docker projects on this machine.
#
# Quick start:
#   export JWT_SECRET="YourSecure32CharacterSecretHere!"  # or set in .env
#   docker compose up -d
#   docker compose logs -f api
#
# IMPORTANT: JWT_SECRET must be set via environment variable or .env file
# =============================================================================

name: nexus-backend

services:
  # ---------------------------------------------------------------------------
  # API Service (ASP.NET Core 8)
  # ---------------------------------------------------------------------------
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: nexus-backend-api
    ports:
      - "5080:8080"  # Host:Container - Access at http://localhost:5080
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - ConnectionStrings__DefaultConnection=Host=db;Port=5432;Database=nexus_dev;Username=postgres;Password=postgres
      # JWT_SECRET MUST be provided via environment variable or .env file
      # DO NOT hardcode secrets here - the app will fail to start without this
      - Jwt__Secret=${JWT_SECRET:?JWT_SECRET environment variable is required}
      - Jwt__Issuer=
      - Jwt__Audience=
      - Cors__AllowedOrigins__0=http://localhost:5080
      - Cors__AllowedOrigins__1=http://localhost:5170
      - Cors__AllowedOrigins__2=http://localhost:5180
      # Rate limiting (relaxed for development)
      - RateLimiting__Auth__PermitLimit=10
      - RateLimiting__Auth__WindowSeconds=60
      - RateLimiting__General__PermitLimit=200
      - RateLimiting__General__WindowSeconds=60
      # RabbitMQ configuration
      - RabbitMq__Host=rabbitmq
      - RabbitMq__Port=5672
      - RabbitMq__Username=guest
      - RabbitMq__Password=guest
      - RabbitMq__VirtualHost=/
      - RabbitMq__ExchangeName=nexus.events
      - RabbitMq__Enabled=true
      # Llama AI service configuration
      - LlamaService__BaseUrl=http://llama-service:11434
      - LlamaService__Model=llama3.2:3b
      - LlamaService__TimeoutSeconds=180
    depends_on:
      db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      llama-service:
        condition: service_started
    networks:
      - nexus-backend-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      start_period: 30s
      retries: 3

  # ---------------------------------------------------------------------------
  # Database (PostgreSQL 16)
  # ---------------------------------------------------------------------------
  db:
    image: postgres:16.4-bookworm
    container_name: nexus-backend-db
    # DB is internal-only by default (no host port exposed)
    # Uncomment the next two lines if you need direct DB access from host:
    # ports:
    #   - "5435:5432"
    environment:
      POSTGRES_DB: nexus_dev
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - nexus-backend-db-data:/var/lib/postgresql/data
    networks:
      - nexus-backend-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d nexus_dev"]
      interval: 5s
      timeout: 5s
      retries: 5

  # ---------------------------------------------------------------------------
  # Message Broker (RabbitMQ)
  # ---------------------------------------------------------------------------
  rabbitmq:
    image: rabbitmq:3.13-management
    container_name: nexus-backend-rabbitmq
    ports:
      - "5672:5672"   # AMQP protocol
      - "15672:15672" # Management UI (http://localhost:15672)
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    volumes:
      - nexus-backend-rabbitmq-data:/var/lib/rabbitmq
    networks:
      - nexus-backend-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 10s
      timeout: 10s
      retries: 5

  # ---------------------------------------------------------------------------
  # AI Service (Ollama with Llama 3.2)
  # ---------------------------------------------------------------------------
  # NOTE: After starting, you must pull the model:
  #   docker compose exec llama-service ollama pull llama3.2:3b
  # ---------------------------------------------------------------------------
  llama-service:
    image: ollama/ollama:latest
    container_name: nexus-backend-llama
    ports:
      - "11434:11434"  # Ollama API port
    environment:
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - nexus-backend-llama-models:/root/.ollama
    networks:
      - nexus-backend-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      start_period: 120s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

# -----------------------------------------------------------------------------
# Networks (isolated from other Docker projects)
# -----------------------------------------------------------------------------
networks:
  nexus-backend-net:
    name: nexus-backend-net
    driver: bridge

# -----------------------------------------------------------------------------
# Volumes (persistent, isolated)
# -----------------------------------------------------------------------------
volumes:
  nexus-backend-db-data:
    name: nexus-backend-db-data
  nexus-backend-rabbitmq-data:
    name: nexus-backend-rabbitmq-data
  nexus-backend-llama-models:
    name: nexus-backend-llama-models
